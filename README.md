# Transformers

This is a PyTorch based minimal implementation of the transformers architecture [Attention Is All You Need](https://arxiv.org/abs/1706.03762) by Vaswani et al., 2017

## Components
- Tokenizer (Embedding)
- Module:
    - Attention
    - AddNorm
    - MLP
- Encoder:
- Decoder
    